# -*- coding: utf-8 -*-
"""MITH_Hospital_Readmission_Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1T8-blXCXHjVsngQ8xGfRX3dgijRAa15m

**Libraries**
"""

import pandas as pd
import numpy as np
from scipy.stats import chi2_contingency
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report
from sklearn.ensemble import RandomForestClassifier

df = pd.read_csv('/content/drive/MyDrive/Colab_Works/MITH_Hospital_Readmission_Prediction/Train-1617360447408-1660719685476.csv')
train_data = df.copy()
df1 = pd.read_csv('/content/drive/MyDrive/Colab_Works/MITH_Hospital_Readmission_Prediction/test-1617360461595-1660719701431.csv')
test_data = df1.copy()

"""**Cleaning** for train_data"""

pd.set_option('display.max_columns', None)

display(train_data)

train_data.describe()

"""Insights from the Decribe of train and test data
* Count - It Shows the count of non - nan values
* mean - The average of the each column
* std - The standard devaition means how much the data is spread from the mean.
* min - smallest value in the column
* max - largest value in the column
* 25% - 1st Quartile
* 50% - 2nd Quartile
* 75% - 3rd Quartile
"""

train_data.info()

train_data.isnull().sum()

"""From the Above I have checked the null values , But in that data there values of "?" so i have replaced them with the nan values."""

train_data.replace('?',np.nan,inplace=True)

train_data.isnull().sum()

"""In race Column i have filled nan values with mode"""

train_data['race'].unique()

train_data['race'].fillna(train_data['race'].mode()[0], inplace=True)

"""In medical_specialty Column i have removed non-related data and coverted misspelled data to correct data."""

train_data['medical_specialty'].unique()

remove_values = [
    'PhysicianNotFound',
    'DCPTEAM',
    'Hospitalist',
    'OutreachServices',
    'Speech'
]

train_data['medical_specialty'] = train_data['medical_specialty'].replace(remove_values, np.nan)

train_data['medical_specialty'] = train_data['medical_specialty'].replace(
    'Obsterics&Gynecology-GynecologicOnco',
    'Obstetrics&Gynecology-GynecologicOncology'
)

train_data['medical_specialty'].value_counts(dropna=False)

"""Checking medical_specialty values groupby race"""

train_data.groupby(['race', 'medical_specialty']).size().reset_index(name='count')

train_data['medical_specialty'].isnull().sum()

"""I filled missing medical specialty values using race-wise mode imputation after verifying statistical dependency."""

train_data['medical_specialty'] = (
    train_data
    .groupby('race')['medical_specialty']
    .transform(lambda x: x.fillna(x.mode().iloc[0]))
)

train_data.isna().sum()

"""Removing the Unwanted Columns for Model Learning"""

train_data.drop(columns=['weight', 'X1', 'X2','index','encounter_id', 'patient_id'], inplace=True)

"""Filling Daig columns nan values with **unknown** because The diagnosis columns represent ICD medical codes.

To avoid introducing incorrect medical assumptions, missing diagnosis values were replaced with an explicit "Unknown" category.
"""

diag_cols = ['diag_1', 'diag_2', 'diag_3', 'diag_4']
train_data[diag_cols] = train_data[diag_cols].fillna('Unknown')

train_data['diag_5'] = train_data['diag_5'].astype(str)

train_data.isna().sum().sort_values(ascending=False)

"""Checking Unique Values In each Column"""

pd.DataFrame({
    'unique': train_data.nunique(),
    'dtype': train_data.dtypes
}).sort_values('unique')

"""removing unwanted columns for ml"""

train_data.drop(columns=['X8','X25','X19','X18'], inplace=True)

train_data.shape

train_data.info()

"""**Cleaning** for test_data"""

display(test_data)

test_data.describe()

test_data.replace('?',np.nan,inplace=True)

test_data.isna().sum().sort_values(ascending=False)

test_data['race'].unique()

test_data['race'].fillna(test_data['race'].mode()[0], inplace=True)

test_data['medical_specialty'].unique()

remove_values = [
    'PhysicianNotFound',
    'OutreachServices',
]
test_data['medical_specialty'] = test_data['medical_specialty'].replace(remove_values, np.nan).replace(
        'Obsterics&Gynecology-GynecologicOnco',
        'Obstetrics&Gynecology-GynecologicOncology')

test_data['medical_specialty'].value_counts(dropna=False)

test_data['medical_specialty'] = (
    test_data
    .groupby('race')['medical_specialty']
    .transform(lambda x: x.fillna(x.mode().iloc[0]))
)

test_data.isna().sum()

test_data.drop(columns=['weight', 'X1', 'X2','index','encounter_id', 'patient_id'], inplace=True)

diag_cols = ['diag_1', 'diag_2', 'diag_3', 'diag_4']
test_data[diag_cols] = test_data[diag_cols].fillna('Unknown')

test_data['diag_5'] = test_data['diag_5'].astype(str)

test_data.isna().sum().sort_values(ascending=False)

pd.DataFrame({
    'unique': test_data.nunique(),
    'dtype': test_data.dtypes
}).sort_values('unique')

test_data.drop(columns=['X16','X8','X25','X19','X18'], inplace=True)

test_data.shape

test_data.info()

"""checking what are xtra data present from test and train data."""

set(test_data['medical_specialty']) - set(train_data['medical_specialty'])

"""**Encoding** For each Columns if required

**Label Encoding for Specific columns**
"""

y_train = train_data['readmitted']
X_train = train_data.drop(columns=['readmitted'])

X_test = test_data.copy()

num_cols = X_train.select_dtypes(include=['int64','float64']).columns.tolist()

cat_cols = X_train.select_dtypes(include=['object']).columns.tolist()

"""**Ordinal Encoding**"""

age_order = [
    '[0-10)','[10-20)','[20-30)','[30-40)',
    '[40-50)','[50-60)','[60-70)',
    '[70-80)','[80-90)','[90-100)'
]

age_map = {v: i for i, v in enumerate(age_order)}

X_train['age'] = X_train['age'].map(age_map)
X_test['age'] = X_test['age'].map(age_map)

"""**ordinal Encoding**"""

from sklearn.preprocessing import OrdinalEncoder

label_cols = [
    'gender','diabetesMed','change',
    'X11','X14','X17','X21','X22'
]

oe = OrdinalEncoder(
    handle_unknown='use_encoded_value',
    unknown_value=-1
)

# fit on TRAIN
X_train[label_cols] = oe.fit_transform(X_train[label_cols])

# transform TEST safely
X_test[label_cols] = oe.transform(X_test[label_cols])

"""**One-Hot Encoding**"""

X_train = pd.get_dummies(X_train, columns=['race'], drop_first=True)
X_test  = pd.get_dummies(X_test,  columns=['race'], drop_first=True)

X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)

"""**Target Encoding**"""

# learn from TRAIN only
med_spec_map = y_train.groupby(X_train['medical_specialty']).mean()

X_train['medical_specialty_enc'] = X_train['medical_specialty'].map(med_spec_map)

global_mean = y_train.mean()
X_test['medical_specialty_enc'] = (
    X_test['medical_specialty']
    .map(med_spec_map)
    .fillna(global_mean)
)

X_train.drop(columns=['medical_specialty'], inplace=True)
X_test.drop(columns=['medical_specialty'], inplace=True)

"""**Frequency Encoding**"""

diag_cols = ['diag_1','diag_2','diag_3','diag_4']

for col in diag_cols:
    freq_map = X_train[col].value_counts()

    X_train[col + '_freq'] = X_train[col].map(freq_map)
    X_test[col + '_freq'] = X_test[col].map(freq_map).fillna(0)

    X_train.drop(columns=[col], inplace=True)
    X_test.drop(columns=[col], inplace=True)

X_train.drop(columns=['diag_5'], inplace=True)
X_test.drop(columns=['diag_5'], inplace=True)

X_train.select_dtypes(include='object').columns

X_train.shape, X_test.shape

X_train.isna().sum().sum(), X_test.isna().sum().sum()

y_train.value_counts(normalize=True)

obj_cols = [
 'X3','X4','X5','X6','X7','X9','X10',
 'X12','X13','X15','X16','X20','X23','X24'
]

for col in obj_cols:
    X_train[col] = X_train[col].astype(str).fillna("MISSING")
    X_test[col] = X_test[col].astype(str).fillna("MISSING")

from sklearn.preprocessing import OrdinalEncoder

oe_all = OrdinalEncoder(
    handle_unknown='use_encoded_value',
    unknown_value=-1
)

X_train[obj_cols] = oe_all.fit_transform(X_train[obj_cols])
X_test[obj_cols] = oe_all.transform(X_test[obj_cols])

obj_cols = X_train.select_dtypes(include='object').columns

"""**Models**

*Logistic regression*
"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report
log_reg = LogisticRegression(
    max_iter=1000,
    class_weight='balanced',
    n_jobs=-1
)

log_reg.fit(X_train, y_train)

train_preds = log_reg.predict(X_train)
train_probs = log_reg.predict_proba(X_train)[:, 1]

print("Train Accuracy:", accuracy_score(y_train, train_preds))
print("Train ROC-AUC:", roc_auc_score(y_train, train_probs))
print(classification_report(y_train, train_preds))

"""**Gradiant Boost**"""

from sklearn.ensemble import GradientBoostingClassifier

gb = GradientBoostingClassifier(
    n_estimators=200,
    learning_rate=0.05,
    max_depth=3,
    random_state=42
)

gb.fit(X_train, y_train)

from sklearn.model_selection import StratifiedKFold, cross_val_score

cv = StratifiedKFold(
    n_splits=5,
    shuffle=True,
    random_state=42
)

cv_scores = cross_val_score(
    gb,
    X_train,
    y_train,
    cv=cv,
    scoring='roc_auc',
    n_jobs=-1
)

print("CV ROC-AUC scores:", cv_scores)
print("Mean CV ROC-AUC:", cv_scores.mean())

from sklearn.metrics import accuracy_score, roc_auc_score, classification_report

train_preds = gb.predict(X_train)
train_probs = gb.predict_proba(X_train)[:, 1]

print("Train Accuracy:", accuracy_score(y_train, train_preds))
print("Train ROC-AUC:", roc_auc_score(y_train, train_probs))
print(classification_report(y_train, train_preds))

test_probs = gb.predict_proba(X_test)[:, 1]
test_preds = (test_probs >= 0.5).astype(int)
print(test_probs[:10])
print(test_preds[:10])

from sklearn.ensemble import GradientBoostingClassifier

# use already-encoded data (DO NOT recreate)
gb_model = GradientBoostingClassifier(
    n_estimators=200,
    learning_rate=0.05,
    max_depth=3,
    random_state=42
)

gb_model.fit(X_train, y_train)

# predict on encoded test data
test_data["pred_readmitted"] = gb_model.predict(X_test)

"""Create a Final O/P file"""

X_test_final = X_test.copy()
X_test_final["pred_readmitted"] = test_preds

X_test_final.head()
X_test_final.shape

X_test_final.to_csv(
    "X_test_with_readmission_prediction.csv",
    index=False
)